---
title: "p8105_hw6_dw3093"
author: "Katherine Wang, dw3093"
output: github_document
---

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(modelr)
library(mgcv)
library(broom)
set.seed(1)
```

#QUESTION 2
# Import the raw data from the guthub
```{r}
homicide_raw <- read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/refs/heads/master/homicide-data.csv",
                          na = c("Unknown", "NA", ""))
```
# Data cleaning, create city_state variable and solved variable
```{r}
homicide <- homicide_raw %>%
  mutate(
    city_state = str_c(city, state, sep = ", "), 
    solved = if_else(disposition == "Closed by arrest", 1, 0),
    victim_age = as.numeric(victim_age)
  ) %>%
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  ) %>%
  drop_na(victim_age, victim_sex, victim_race, solved) 
```

#  Conduct the logistic Regression for Baltimore, MD
```{r}
baltimore_raw <- homicide |> filter(city_state == "Baltimore, MD")
model <- glm(solved ~ victim_age + victim_sex + victim_race,
                       data = baltimore_raw, family = "binomial")
baltimore_results <- broom::tidy(model, conf.int = TRUE) %>%
  filter(term == "victim_sexMale") %>%
  mutate(
    OR = exp(estimate),     
    CI_lower = exp(conf.low), 
    CI_upper = exp(conf.high)
  ) %>%
  select(OR, CI_lower, CI_upper) %>%
  knitr::kable(digits = 3)
baltimore_results
```
The logistic regression analysis for Baltimore, MD, found that the odds of a homicide being solved for male victims are 0.426 times the odds for female victims, holding victim age and race constant. The 95% CI for the odds ratio is (0.324, 0.558), suggesting that the result is statistically significant because the interval does not include 1.

This means there is strong evidence that the likelihood of case resolution differs between male and female victims in Baltimore.

```{r}
city_results <- homicide %>%
  group_by(city_state) %>%
  nest() %>%
  mutate(
    model = map(data, ~glm(solved ~ victim_age + victim_sex + victim_race, 
                           data = ., family = "binomial")),
    results = map(model, ~broom::tidy(., conf.int = TRUE) %>%
                    filter(term == "victim_sexMale") %>%
                    mutate(
                      OR = exp(estimate), 
                      CI_lower = exp(conf.low), 
                      CI_upper = exp(conf.high))
                  )
  ) %>%
  unnest(results) %>%
  select(city_state, OR, CI_lower, CI_upper)  
city_results|>
  knitr::kable(digits = 3)
```
# # Create a plot of OR and CI for each city
```{r}
city_results %>%
  ggplot(aes(x = reorder(city_state, OR), y = OR)) +
  geom_point(color = "pink") +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper), width = .2) + 
  labs(
    title = "Adjusted Odds Ratios for Solving Homicides by City",
    x = "City, State",
    y = "Odds Ratio (Male vs. Female Victims)"
  ) +
  theme_minimal() +
  theme(
    axis.text = element_text(size = 8),
    plot.title = element_text(hjust = 0.5, face = "bold")
  ) +
  coord_flip()
```

Comments: The plot shows the ORs for solving homicides for male victims relative to female victims with CIs. Cities where the CIs exclude 1 indicate significant gender differences, while overlapping CIs suggest no clear disparity. Wide CIs in cities like Albuquerque, Stockton, and Fresno reflect high variability or limited data, reducing precision. In most cities, male victims have lower odds of their cases being solved compared to female victims. However, in Albuquerque, Atlanta, Fresno, Nashville, Stockton, and Richmond, male victims are more likely to have their cases solved.

# QUESTION 3:
# Import the data, conduct data cleaning, and exclude the missing value
```{r}
birthweight = read_csv("data/birthweight.csv", na = c(".", "", "NA")) |>
  drop_na()|>
  mutate(
    malform = factor(malform, levels = c(0, 1), labels = c("Absent", "Present")),
    babysex = factor(babysex, levels = c(1, 2), labels = c("Male", "Female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")),
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8), labels = c("White", "Black", "Asian", "Puerto Rican", "Other"))
  )

colSums(is.na(birthweight))
```
Check missing value: we can see that the summary of the missing values shows all zeros, which means we have successfully excluded all missing values!

# run the regression model
```{r}
full_model <- lm(bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + malform + menarche + mheight + momage + mrace + parity + pnumlbw + pnumsga + ppbmi + ppwt + smoken + wtgain, data = birthweight)

stepwise_model <- step(full_model, direction = "backward")

summary(stepwise_model)
```
```{r}
birthweight <- birthweight %>%
  add_predictions(full_model, var = "fitted_hypothesis") %>%
  add_residuals(full_model, var = "residuals_hypothesis")
ggplot(birthweight, aes(x = fitted_hypothesis, y = residuals_hypothesis)) +
  geom_point(alpha = .5, color = "pink") +
  geom_smooth(method = "loess", color = "purple",) +
  labs(
    title = "Residuals vs. Fitted Values",
    x = "Fitted Values (Predicted Birthweight)",
    y = "Residuals"
  ) +
  theme_minimal() + 
  theme(
    plot.title = element_text(hjust = 0.5, face = "bold"),
    axis.text = element_text(size = 10)
  )
```

The residuals vs. fitted values plot shows that residuals are mostly centered around 0, indicating no substantial systematic bias in the model's predictions. 

```{r}
model_1 <- lm(bwt ~ blength + gaweeks, data = birthweight)
model_2 <- lm(bwt ~ bhead * blength * babysex, data = birthweight)
model_proposed <- lm(bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + malform + menarche + mheight + momage + mrace + parity + pnumlbw + pnumsga + ppbmi + ppwt + smoken + wtgain, data = birthweight)

set.seed(1)
cv <- crossv_mc(birthweight, 100) %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble),
    model_1 = map(train, ~ lm(bwt ~ blength + gaweeks, data = .x)),
    model_2 = map(train, ~ lm(bwt ~ bhead * blength * babysex, data = .x)),
    model_proposed = map(train, ~ lm(bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + malform + menarche + mheight + momage + mrace + parity + pnumlbw + pnumsga + ppbmi + ppwt + smoken + wtgain, data = .x))
  ) %>%
  mutate(
    rmse_1 = map2_dbl(model_1, test, ~ rmse(.x, .y)),
    rmse_2 = map2_dbl(model_2, test, ~ rmse(.x, .y)),
    rmse_proposed = map2_dbl(model_proposed, test, ~ rmse(.x, .y))
  )
cv_summary <- cv %>%
  select(rmse_1, rmse_2, rmse_proposed) %>%
  pivot_longer(cols = everything(), names_to = "model", values_to = "rmse") %>%
  mutate(model = recode(model,
                        "rmse_1" = "Model 1",
                        "rmse_2" = "Model 2",
                        "rmse_proposed" = "Model Proposed")) %>%
  group_by(model) %>%
  summarize(mean_rmse = mean(rmse))
cv_summary %>% knitr::kable(digits = 3)
```
```{r}
cv %>%
  select(starts_with("rmse")) %>%
  pivot_longer(
    everything(), 
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>%
  mutate(model = fct_inorder(model)) %>%
  ggplot(aes(x = model, y = rmse, fill = model)) +
  geom_violin() +
  labs(
    title = "RMSE Comparison Across Three Models",
    x = "Model",
    y = "RMSE"
  ) +
  theme_minimal()
```

Comments: 
Model 1, which includes only birth length and gestational age as predictors, has the highest RMSE and the widest variability, indicating poor predictive performance. Its simplicity limits its ability to account for key factors influencing birthweight, making it the least effective model. 

Model 2 improves upon Model 1 by incorporating head circumference, birth length, sex, and their interactions. This enhancement reduces RMSE and variability, demonstrating better predictive accuracy. 

The proposed model, which includes a comprehensive set of maternal, socioeconomic, and baby-specific predictors, achieves the lowest RMSE and the narrowest variability, reflecting its superior ability to predict birthweight. While it is the most accurate and reliable model, its complexity could pose challenges for practical application and interpretation, especially in resource-constrained settings. In contrast, Model 2 offers a reasonable trade-off between simplicity and predictive performance, making it a more practical option
